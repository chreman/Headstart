"doi","id","subject","title","authors","year","publisher","resulttype","language","journal","url","paper_abstract","project_id","accessright","x","y","area_uri","cluster_labels","area","citation_count","cited_by_tweeters_count","readers.mendeley","readers","file_hash"
"10.1007/978-3-319-16811-1_5","dedup_wf_001::31889f0b2dd24234c51fba40654b1a01","conditional random fields","A high performance CRF model for clothes parsing","Simó Serra, Edgar","2014-01-01","Springer","publication","","","","In this paper we tackle the problem of clothing parsing: Our goal is to segment and classify different garments a person is wearing. We frame the problem as the one of inference in a pose-aware Conditional Random Field (CRF) which exploits appearance, figure/ground segmentation, shape and location priors for each garment as well as similarities between segments, and symmetries between different human body parts. We demonstrate the effectiveness of our approach on the Fashionista dataset and show that we can obtain a significant improvement over the state-of-the-art.
			Peer Reviewed","287654","Open Access","0.096","-0.5612","3","Clothes parsing, Conditional random fields, Performance crf model","Clothes parsing, Conditional random fields, Performance crf model","7",NA,NA,"",""
"10.1016/j.engappai.2014.06.025","dedup_wf_001::1cdb3a1c43ca47d3fd1ca5c6936df8b1","Garment part detection","Learning RGB-D descriptors of garment parts for informed robot grasping","Ramisa, Arnau","2014-01-01","Elsevier","publication","","","","Robotic handling of textile objects in household environments is an emerging application that has recently received considerable attention thanks to the development of domestic robots. Most current approaches follow a multiple re-grasp strategy for this purpose, in which clothes are sequentially grasped from different points until one of them yields a desired configuration.



			In this work we propose a vision-based method, built on the Bag of Visual Words approach, that combines appearance and 3D information to detect parts suitable for grasping in clothes, even when they are highly wrinkled.



			We also contribute a new, annotated, garment part dataset that can be used for benchmarking classification, part detection, and segmentation algorithms. The dataset is used to evaluate our approach and several state-of-the-art 3D descriptors for the task of garment part detection. Results indicate that appearance is a reliable source of information, but that augmenting it with 3D information can help the method perform better with new clothing items.
			Peer Reviewed","269959","Open Access","0.4172","-0.3082","3","Clothes parsing, Conditional random fields, Performance crf model","Clothes parsing, Conditional random fields, Performance crf model","9",NA,NA,"",""
"10.1016/j.engappai.2015.08.013","dedup_wf_001::82fa60e87111550ccf8c8972d65e258a","[INFO.INFO-AI] Computer Science [cs]/Artificial Intelligence [cs.AI]","Engineering Multiuser Museum Interactives for Shared Cultural Experiences","Confalonieri, Roberto","2015-01-01","Elsevier","publication","","Engineering Applications of Artificial Intelligence","https://hal.archives-ouvertes.fr/hal-01592023/document","International audience; Multiuser museum interactives are computer systems installed in museums or galleries which allow several visitors to interact together with digital representations of artefacts and information from the museum׳s collection. In this paper, we describe WeCurate, a socio-technical system that supports co-browsing across multiple devices and enables groups of users to collaboratively curate a collection of images, through negotiation, collective decision making and voting. The engineering of such a system is challenging since it requires to address several problems such as: distributed workflow control, collective decision making and multiuser synchronous interactions. The system uses a peer-to-peer Electronic Institution (EI) to manage and execute a distributed curation workflow and models community interactions into scenes, where users engage in different social activities. Social interactions are enacted by intelligent agents that interface the users participating in the curation workflow with the EI infrastructure. The multiagent system supports collective decision making, representing the actions of the users within the EI, where the agents advocate and support the desires of their users e.g. aggregating opinions for deciding which images are interesting enough to be discussed, and proposing interactions and resolutions between disagreeing group members. Throughout the paper, we describe the enabling technologies of WeCurate, the peer-to-peer EI infrastructure, the agent collective decision making capabilities and the multi-modal interface. We present a system evaluation based on data collected from cultural exhibitions in which WeCurate was used as supporting multiuser interactive.","287654","Open Access","-0.2858","0.5119","2","[info.info-ai] computer science [cs]/artificial intelligence [cs.ai]","[info.info-ai] computer science [cs]/artificial intelligence [cs.ai]","1","1","37","",""
"10.1109/cvpr.2014.71","dedup_wf_001::4bfd2bcf74efc53409cfd983e7ed200c",":Pattern recognition::Computer vision [Classificació INSPEC]","Very fast solution to the PnP problem with algebraic outlier rejection","Ferraz, Luis","2014-01-01","Institute of Electrical and Electronics Engineers","publication","","","","We propose a real-time, robust to outliers and accurate solution to the Perspective-n-Point (PnP) problem. The main advantages of our solution are twofold: first, it integrates the outlier rejection within the pose estimation pipeline with a negligible computational overhead; and second, its scalability to arbitrarily large number of correspondences. Given a set of 3D-to-2D matches, we formulate pose estimation problem as a low-rank homogeneous system where the solution lies on its 1D null space. Outlier correspondences are those rows of the linear system which perturb the null space and are progressively detected by projecting them on an iteratively estimated solution of the null space. Since our outlier removal process is based on an algebraic criterion which does not require computing the full-pose and reprojecting back all 3D points on the image plane at each step, we achieve speed gains of more than 100× compared to RANSAC strategies. An extensive experimental evaluation will show that our solution yields accu- rate results in situations with up to 50% of outliers, and can process more than 1000 correspondences in less than 5ms.
			Peer Reviewed","287654","Open Access","-0.5992","0.0448","6",":pattern recognition::computer vision [classificació inspec]",":pattern recognition::computer vision [classificació inspec]","15",NA,NA,"",""
"10.1109/icra.2014.6907591","dedup_wf_001::50e4f81208373f98525dcb8ce1cd40b2",":Enginyeria de la telecomunicació::Processament del senyal::Reconeixement de formes [Àrees temàtiques de la UPC]","Fast online learning and detection of natural landmarks for autonomous aerial robots","Villamizar, Michael","2014-01-01","Institute of Electrical and Electronics Engineers","publication","","","","We present a method for efficiently detecting natural landmarks that can handle scenes with highly repetitive patterns and targets progressively changing its appearance. At the core of our approach lies a Random Ferns classifier, that models the posterior probabilities of different views of the target using multiple and independent Ferns, each containing features at particular positions of the target. A Shannon entropy measure is used to pick the most informative locations of these features. This minimizes the number of Ferns while maximizing its discriminative power, allowing thus, for robust detections at low computational costs. In addition, after offline initialization, the new incoming detections are used to update the posterior probabilities on the fly, and adapt to changing appearances that can occur due to the presence of shadows or occluding objects. All these virtues, make the proposed detector appropriate for UAV navigation. Besides the synthetic experiments that will demonstrate the theoretical benefits of our formulation, we will show applications for detecting landing areas in regions with highly repetitive patterns, and specific objects under the presence of cast shadows or sudden camera motions.","287617","Open Access","0.5385","0.119","5",":enginyeria de la telecomunicació::processament del senyal::reconeixement de formes [àrees temàtiques de la upc]",":enginyeria de la telecomunicació::processament del senyal::reconeixement de formes [àrees temàtiques de la upc]","5",NA,NA,"",""
"10.1186/1743-0003-7-11","od______2658::c80042e2355e88e21321989b8e3b407d","user centric","Understanding the Everyday Use of Head-Worn Computers","Vogl, Anita","2015-01-01","","publication","","","","Early research on head-worn computers (HWCs)
			has focused on hardware and specific applications. However,
			there is little research about the everyday usage of head-worn
			computers in particular aspects such as: context of use, social
			acceptance across different activities, audiences and interaction
			techniques. This paper provides insights into the use of head-
			worn computers by capturing the opinions of novice and expert
			users through a survey, a three-week diary study, and interviews.
			The overarching finding is that the context of use is critical, ei-
			ther due to the need to support micro-interactions, or because the
			interaction paradigm itself should depend on the context of use.","287654","Open Access","0.1641","0.6224","4","User centric","User centric","12",NA,NA,"",""
"10.3233/978-1-61499-452-7-273","dedup_wf_001::ebbcb625aad364247c2bcf4a0f83d52a","Large-scale image classification","Evaluation of random forests on large-scale classification problems using a bag-of-visual-words representation","Solé, Xavier","2014-01-01","IOS Press","publication","","","","Random Forest is a very efficient classification method that has shown success in tasks like image segmentation or object detection, but has not been applied yet in large-scale image classification scenarios using a Bag-of-Visual-Words representation. In this work we evaluate the performance of Random Forest on the ImageNet dataset, and compare it to standard approaches in the state-of-the-art.
			Peer Reviewed","287654","Open Access","-0.3309","-0.4287","1","Large-scale image classification","Large-scale image classification","",NA,NA,"",""
