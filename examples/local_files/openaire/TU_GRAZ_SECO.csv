"doi","id","subject","title","authors","year","publisher","resulttype","language","journal","url","paper_abstract","project_id","accessright","x","y","area_uri","cluster_labels","area","citation_count","cited_by_tweeters_count","readers.mendeley","readers","file_hash"
"","dedup_wf_001::244c12a819ce9ddaeaa3cd7649b54302","[SDV.NEU] Life Sciences [q-bio]/Neurons and Cognition [q-bio.NC]","Hierarchical order in the cortex.","Vezoli, Julien","2010-08-06","HAL CCSD","publication","","","https://hal.archives-ouvertes.fr/hal-00553406/document","Strong regularities of early visual areas interconnections led to the suggestion that rostral directed connections are feedforward (FF) pathways channelling information from lower to higher order areas, while caudal directed connections constitute feedback (FB) pathways (Rockland and Pandya, 1979). Analysis of these pathways in primate enabled the identification of a hierarchical organization (Felleman and Van Essen, 1991), providing a major conceptual framework for understanding structure-function relationships of the cortex. Because previous description of cortical topology have been restricted to binary connectivity leading to strong indeterminacy (Hilgetag et al., 1996), we re-examined network description of cortex structure by making retrograde tracer injections in areas spanning all cortical lobes. We used quantitative tools to estimate hierarchical distance and relative weights of connections (Barone et al., 2000, Vezoli et al., 2004) and used computational modeling analysis to analyse the underlying hierarchical structure of cortical networks. Comparing weighted and unweighted analyses, we demonstrated a significant hierarchical tendency in the pattern of laminar relations between cortical areas. Further, we evidenced a highly parallel system with high degree of reciprocity and found that rare pairs of areas are reciprocally connected by FF connections, constituting unexpected descending paths (Crick and Koch, 1998) in an otherwise surprisingly hierarchical system of cortical areas.","216593","Open Access","-0.2871","0.5879","7","[sdv.neu] life sciences [q-bio]/neurons and cognition [q-bio.nc], Cortical networks","[sdv.neu] life sciences [q-bio]/neurons and cognition [q-bio.nc], Cortical networks",NA,NA,NA,"",""
"","ec_fp7_ict__::aec98c8d8c6f8ee1705b410b2c9b7c4d","cortex explained;explained reward;functional network","Functional network reorganization in motor cortex can be explained by reward-modulated Hebbian learning","#N/D","2009-01-01","","publication","","","","","216593","Closed Access","0.2612","-0.5049","8","Modulated hebbian learning, Reward modulated hebbian, Decision making","Modulated hebbian learning, Reward modulated hebbian, Decision making",NA,NA,NA,"",""
"","ec_fp7_ict__::e5fc1acfb5538ebbae7cc2d927616937","analysis spiking;classification learning;feature analysis","Replacing supervised classification learning by slow feature analysis in spiking neural networks","#N/D","2009-01-01","","publication","","","","","216593","Closed Access","0.3484","-0.4231","3","Classification learning, Emergent pattern, Feature analysis","Classification learning, Emergent pattern, Feature analysis",NA,NA,NA,"",""
"","ec_fp7_ict__::86e8658ac80fd3f464f5f7843b9cc6ca","detect hidden;enables spiking;hidden inputs","STDP enables spiking neurons to detect hidden causes of their inputs","#N/D","2009-01-01","","publication","","","","","216593","Closed Access","-0.1351","-0.6952","10","Spiking neurons, Computation in recurrent, Detect hidden","Spiking neurons, Computation in recurrent, Detect hidden",NA,NA,NA,"",""
"10.1002/cne.23820","od_______908::333827f30abf7dc34fe91a21901a0749","cell lineages","Unsupervised lineage?based characterization of primate precursors reveals high proliferative and morphological diversity in the OSVZ","Pfeiffer, Michael","2015-07-01","John Wiley and Sons Inc.","publication","","The Journal of Comparative Neurology","","ABSTRACT Generation of the primate cortex is characterized by the diversity of cortical precursors and the complexity of their lineage relationships. Recent studies have reported miscellaneous precursor types based on observer classification of cell biology features including morphology, stemness, and proliferative behavior. Here we use an unsupervised machine learning method for Hidden Markov Trees (HMTs), which can be applied to large datasets to classify precursors on the basis of morphology, cell?cycle length, and behavior during mitosis. The unbiased lineage analysis automatically identifies cell types by applying a lineage?based clustering and model?learning algorithm to a macaque corticogenesis dataset. The algorithmic results validate previously reported observer classification of precursor types and show numerous advantages: It predicts a higher diversity of progenitors and numerous potential transitions between precursor types. The HMT model can be initialized to learn a user?defined number of distinct classes of precursors. This makes it possible to 1) reveal as yet undetected precursor types in view of exploring the significant features of precursors with respect to specific cellular processes; and 2) explore specific lineage features. For example, most precursors in the experimental dataset exhibit bidirectional transitions. Constraining the directionality in the HMT model leads to a reduction in precursor diversity following multiple divisions, thereby suggesting that one impact of bidirectionality in corticogenesis is to maintain precursor diversity. In this way we show that unsupervised lineage analysis provides a valuable methodology for investigating fundamental features of corticogenesis. J. Comp. Neurol. 524:535?563, 2016. ? 2015 The Authors The Journal of Comparative Neurology Published by Wiley Periodicals, Inc.","216593","Open Access","0.5345","0.1527","11","Lineage based characterization, Cell lineages, Characterization of primate","Lineage based characterization, Cell lineages, Characterization of primate","5",NA,NA,"",""
"10.1007/978-3-642-15822-3_50","ec_fp7_ict__::707b1e4003ac41240d2714b9da24dee3","basis translation;translation invariance;mappings basis","Self-organization of steerable topographic mappings as basis for translation invariance","Zhu J.","2010-01-01","","publication","","","","","216593","Closed Access","0.7253","0.3498","9","Bilinear networks, Invariant recognition, Translation invariance","Bilinear networks, Invariant recognition, Translation invariance","3",NA,NA,"",""
"10.1007/s00422-012-0471-0","dedup_wf_001::2ad8666c918f5326da34a8d930118de2","Department of Informatics","Towards a theoretical foundation for morphological computation with compliant bodies","Hauser, Helmut","2011-01-01","SPRINGER","publication","","BIOLOGICAL CYBERNETICS","http://www.zora.uzh.ch/id/eprint/72786/1/Hauser_et_al_Towards_theoretical_foundation.pdf","The control of compliant robots is, due to their often nonlinear and complex dynamics, inherently difficult. The vision of morphological computation proposes to view these aspects not only as problems, but rather also as parts of the solution. Non-rigid body parts are not seen anymore as imperfect realizations of rigid body parts, but rather as potential computational resources. The applicability of this vision has already been demonstrated for a variety of complex robot control problems. Nevertheless, a theoretical basis for understanding the capabilities and limitations of morphological computation has been missing so far. We present a model for morphological computation with compliant bodies, where a precise mathematical characterization of the potential computational contribution of a complex physical body is feasible. The theory suggests that complexity and nonlinearity, typically unwanted properties of robots, are desired features in order to provide computational power. We demonstrate that simple generic models of physical bodies, based on mass-spring systems, can be used to implement complex nonlinear operators. By adding a simple readout (which is static and linear) to the morphology such devices are able to emulate complex mappings of input to output streams in continuous time. Hence, by outsourcing parts of the computation to the physical body, the difficult problem of learning to control a complex body, could be reduced to a simple and perspicuous learning task, which can not get stuck in local minima of an error function.","248311","Open Access","-0.6357","-0.3569","10","Spiking neurons, Computation in recurrent, Detect hidden","Spiking neurons, Computation in recurrent, Detect hidden","69","3","94","",""
"10.1007/s00429-017-1384-4","dedup_wf_001::d7e535f4cdcb23034f94fc5953c44567","Original Article","Synaptic connections formed by patchy projections of pyramidal cells in the superficial layers of cat visual cortex","Koestinger, German","2017-02-01","Springer Berlin Heidelberg","publication","","Brain Structure & Function","","The present study is the first to describe quantitatively the patterns of synaptic connections made by the patchy network of pyramidal cell axons in the superficial layers of cat V1 in relation to the orientation map. Intrinsic signal imaging of the orientation map was combined with 3D morphological reconstructions of physiologically-characterized neurons at light and electron microscope levels. A Similarity Index (SI) expressed the similarity of the orientation domain of a given bouton cluster to that of its parent dendritic tree. Six pyramidal cells whose axons had a wide range of SIs were examined. Boutons were sampled from five local and five distal clusters, and from the linear segments that link the clusters. The synaptic targets were reconstructed by serial section electron microscopy. Of the 233 synapses examined, 182 synapses were formed with spiny neurons, the remainder with smooth neurons. The proportion of smooth neurons that were synaptic targets varied greatly (from 0 to 50%) between the cluster samples, but was not correlated with the SI. The postsynaptic density sizes were similar for synapses in local and distal clusters, regardless of their SI. This heterogeneity in the synaptic targets of single cells within the superficial layers is a network feature well-suited for context-dependent processing.","216593","Open Access","-0.5391","0.1383","1","Visual cortex, Pyramidal cells","Visual cortex, Pyramidal cells","2",NA,NA,"",""
"10.1016/b978-0-444-53860-4.00016-7","dedup_wf_001::44f9391fa6ede3897c2c4eed59bd1d8c","[SDV.NEU.NB] Life Sciences [q-bio]/Neurons and Cognition [q-bio.NC]/Neurobiology","Self-organization and interareal networks in the primate cortex.","Kennedy, Henry","2012-01-01","HAL CCSD","publication","","","https://hal.archives-ouvertes.fr/hal-00663248/document","International audience; Variability of gene expression of cortical precursors may partially reflect the operation of the gene regulatory network and determines the boundaries of the state space within which self-organization of the cortex can unfold. In primates, including humans, the outer subventricular zone, a primate-specific germinal zone, generates a large contingent of the projection neurons participating in the interareal network. The number of projection neurons in individual pathways largely determines the network properties as well as the hierarchical organization of the cortex. Mathematical modeling of cell-cycle kinetics of cortical precursors in the germinal zones reveals how multiple control loops ensure the generation of precise numbers of different categories of projection neurons and allow partial simulation of cortical self-organization. We show that molecular manipulation of the cell cycle of cortical precursors shifts the trajectory of the cortical precursor within its state space, increases the diversity in the cortical lineage tree, and explores changes in phylogenetic complexity. These results explore how self-organization underlies the complexity of the cortex and suggest evolutionary mechanisms.","216593","Open Access","0.0958","0.3057","11","Lineage based characterization, Cell lineages, Characterization of primate","Lineage based characterization, Cell lineages, Characterization of primate","10",NA,NA,"",""
"10.1016/j.celrep.2013.12.026","dedup_wf_001::5fa6679aa0e401b3c0ad2c79d5578121","Biology (General)","Mitotic Spindle Asymmetry: A Wnt/PCP-Regulated Mechanism Generating Asymmetrical Division in Cortical Precursors","Delaunay, Delphine","2014-01-01","CELL PRESS","publication","","CELL REPORTS","","The regulation of asymmetric cell division (ACD) during corticogenesis is incompletely understood. We document that spindle-size asymmetry (SSA) between the two poles occurs during corticogenesis and parallels ACD. SSA appears at metaphase and is maintained throughout division, and we show it is necessary for proper neurogenesis. Imaging of spindle behavior and division outcome reveals that neurons preferentially arise from the larger-spindle pole. Mechanistically, SSA magnitude is controlled by Wnt7a and Vangl2, both members of the Wnt/planar cell polarity (PCP)-signaling pathway, and relayed to the cell cortex by P-ERM proteins. In vivo, Vangl2 and P-ERM downregulation promotes early cell-cycle exit and prevents the proper generation of late-born neurons. Thus, SSA is a core component of ACD that is conserved in invertebrates and vertebrates and plays a key role in the tight spatiotemporal control of self-renewal and differentiation during mammalian corticogenesis.","216593","Open Access","-0.5639","-0.4464","4","Generating asymmetrical division, Asymmetry a wnt, Biology (general)","Generating asymmetrical division, Asymmetry a wnt, Biology (general)","28","4","74","",""
"10.1016/j.conb.2015.12.010","dedup_wf_001::c058939c4251b1eab2d6a35494e779f6","[SDV.NEU] Life Sciences [q-bio]/Neurons and Cognition [q-bio.NC]","Principles of inter-areal connections of the macaque cortex","Markov, Nikola","2010-08-06","HAL CCSD","publication","","","https://hal.archives-ouvertes.fr/hal-00553400/document","The operation of real world networks is largely determined by their weighted and spatial characteristics. Surprisingly little is known about these features in cortex. We generated in macaque, a consistent database of inter-areal connections comprising projection densities (link weights) and physical lengths. Contrary to previous assumptions, the cortical connection matrix is dense (66%) and therefore, not a small-world graph. Link weights are both highly specific and heterogeneous and we show that it is these properties that characterize the network. The embedding of this weighted network is governed by a distance rule that predicts both its binary features as well as the global and local communication efficiencies. Analysis of the efficiency of this weighted network suggests that small changes in global communication efficiency are offset by large changes in local efficiency. These findings indicate a weight-based hierarchical layering in cortical architecture and processing.","216593","Open Access","-0.1893","0.4632","7","[sdv.neu] life sciences [q-bio]/neurons and cognition [q-bio.nc], Cortical networks","[sdv.neu] life sciences [q-bio]/neurons and cognition [q-bio.nc], Cortical networks","14","11","138","",""
"10.1016/j.jneumeth.2010.12.011","dedup_wf_001::3fc478cb17cedfb6c2297c200a769475","Neuroscience(all)","Automated analysis of neuronal morphology, synapse number and synaptic recruitment","Schmitz S.K.","2011-01-01","Elsevier BV","publication","","Journal of Neuroscience Methods","","","216593","Open Access","-0.485","-0.5222","1","Visual cortex, Pyramidal cells","Visual cortex, Pyramidal cells","57",NA,NA,"",""
"10.1016/j.neuroimage.2013.04.031","dedup_wf_001::4aa36f9989190c966ffadab98f292acf","MESH : Cerebral Cortex","Why data coherence and quality is critical for understanding interareal cortical networks","Kennedy, Henry","2013-01-01","ACADEMIC PRESS INC ELSEVIER SCIENCE","publication","","NEUROIMAGE","https://hal.archives-ouvertes.fr/hal-00818869/document","International audience; Numerous studies have investigated inter-areal cortical networks using either diffusion MRI or axonal tract-tracing. While both techniques have been used in non-human primates only diffusion MRI can be used in human. The advantage of axonal tract-tracing is that unlike diffusion MRI it has a high single-cell resolution, and most importantly gives the laminar origins and terminations of inter-areal pathways. It, therefore, can be used to obtain the weighted and directed cortical graph. Axonal tract tracing has traditionally been collated from multiple experiments in order to determine the large-scale inter-areal network. Collated data of this kind present numerous problems due to lack of coherence across studies and incomplete exploitation. We have therefore developed a consistent data base which uses standardized experimental and parcellation procedures across brains. Here we review our recent publications analyzing the consistent database obtained from retrograde tracer injections in 29 cortical areas in a parcellation of 91 areas of the macaque cortex. Compared to collated data, our results show that the cortical graph is dense. Density is a graph theoretic measure, and refers to the number of observed connections in a square matrix expressed as a percentage of the possible connections. In our database 66% of the connections that can exist do exist which is considerably higher than the graph densities reported in studies using collated data (7-32%). The consistent data base reports 37% more pathways than previously reported, many of which are unidirectional. This latter and unexpected property has not been reported in earlier studies. Given the high density, the resulting cortical graph shows other unexpected properties. Firstly, the binary specificity is considerably higher than expected. As we show, this property is a consequence of the inter-areal connection probability declining with distance. Secondly, small groups of areas are found to receive high numbers of inputs. This is termed a high domination and is analyzed by a graph theoretic procedure known as a minimum dominating set analysis. We discuss these findings with respect to the long-distance connections, over half of which were previously not reported. These so called new found projections display high specificities and play an important integration role across large regions. It is to be expected that the future examination of the 62 remaining areas will disclose further levels of complexity and enable construction of a weighted directed graph revealing the hierarchical complexity of the cortex.","216593","Open Access","-0.1827","0.6118","7","[sdv.neu] life sciences [q-bio]/neurons and cognition [q-bio.nc], Cortical networks","[sdv.neu] life sciences [q-bio]/neurons and cognition [q-bio.nc], Cortical networks","20",NA,"161","",""
"10.1016/j.neuroimage.2013.04.054","webcrawl____::6a7cda189103ba7cfecc3f87a3177a5f","brain circuits;circuits survive;microscopic connectome","Sparse reconstruction of brain circuits: Or, how to survive without a microscopic connectome","da Costa, Nuno Macarico","2013-01-01","ACADEMIC PRESS INC ELSEVIER SCIENCE","publication","","NEUROIMAGE","","","216593","Closed Access","0.658","-0.4094","2","Bigger brains, Brain circuits, Cell division","Bigger brains, Brain circuits, Cell division","15","30","195","",""
"10.1016/j.neuron.2013.07.036","dedup_wf_001::60200bf4a6609f2149cec3b008281e15","Neuroscience(all)","A Predictive Network Model of Cerebral Cortical Connectivity Based on a Distance Rule","Ercsey-Ravasz, Mária","2013-10-01","Elsevier BV","publication","","Neuron","","Recent advances in neuroscience have engendered interest in large-scale brain networks. Using a consistent database of corticocortical connectivity, generated from hemisphere-wide, retrograde tracing experiments in the macaque, we analyzed interareal weights and distances to reveal an important organizational principle of brain connectivity. Using appropriate graph theoretical measures, we show that although very dense (66%), the interareal network has strong structural specificity. Connection weights exhibit a heavy-tailed lognormal distribution spanning five orders of magnitude and conform to a distance rule reflecting exponential decay with interareal separation. A single-parameter random graph model based on this rule predicts numerous features of the cortical network: (1) the existence of a network core and the distribution of cliques, (2) global and local binary properties, (3) global and local weight-based communication efficiencies modeled as network conductance, and (4) overall wire-length minimization. These findings underscore the importance of distance and weight-based heterogeneity in cortical architecture and processing.","5R01MH060974-17","Open Access","-0.1056","0.3871","7","[sdv.neu] life sciences [q-bio]/neurons and cognition [q-bio.nc], Cortical networks","[sdv.neu] life sciences [q-bio]/neurons and cognition [q-bio.nc], Cortical networks","95","28","46","",""
"10.1016/j.neuron.2013.09.032","dedup_wf_001::cb28e5a25e539304b05736cc25a600c1","Neuroscience(all)","Precursor Diversity and Complexity of Lineage Relationships in the Outer Subventricular Zone of the Primate","Betizeau, Marion","2013-01-01","CELL PRESS","publication","","NEURON","","","216593","Open Access","0.7675","0.0605","11","Lineage based characterization, Cell lineages, Characterization of primate","Lineage based characterization, Cell lineages, Characterization of primate","127",NA,NA,"",""
"10.1016/j.tics.2009.11.005","dedup_wf_001::e71b72fc981cea0ad2674f5f72a23f08","Article","Perceptual learning rules based on reinforcers and attention","Roelfsema P.R.","2010-01-01","","publication","","Trends in Cognitive Sciences","","How does the brain learn those visual features that are relevant for behavior? In this article, we focus on two factors that guide plasticity of visual representations. First, reinforcers cause the global release of diffusive neuromodulatory signals that gate plasticity. Second, attentional feedback signals highlight the chain of neurons between sensory and motor cortex responsible for the selected action. We here propose that the attentional feedback signals guide learning by suppressing plasticity of irrelevant features while permitting the learning of relevant ones. By hypothesizing that sensory signals that are too weak to be perceived can escape from this inhibitory feedback, we bring attentional learning theories and theories that emphasized the importance of neuromodulatory signals into a single, unified framework.","216593","Open Access","0.0748","-0.655","8","Modulated hebbian learning, Reward modulated hebbian, Decision making","Modulated hebbian learning, Reward modulated hebbian, Decision making","105",NA,NA,"",""
"10.1038/cdd.2010.102","dedup_wf_001::f3c993c35d16646c91661c29dd06de74","Original Paper","Primate-specific RFPL1 gene controls cell-cycle progression through cyclin B1/Cdc2 degradation","Bonnefont, J","2010-08-20","Nature Publishing Group","publication","","CELL DEATH AND DIFFERENTIATION","","Ret finger protein-like 1 (RFPL1) is a primate-specific target gene of Pax6, a key transcription factor for pancreas, eye and neocortex development. However, its cellular activity remains elusive. In this article, we report that Pax6-elicited expression of the human (h)RFPL1 gene in HeLa cells can be enhanced by in vivo p53 binding to its promoter and therefore investigated the hypothesis that hRFPL1 regulates cell-cycle progression. Upon expression in these cells, hRFPL1 decreased cell number through a kinase-dependent mechanism as PKC activates and Cdc2 inhibits hRFPL1 activity. hRFPL1 antiproliferative activity led to an increased cell population in G2/M phase and specific cyclin B1 and Cdc2 downregulations, which were precluded by a proteasome inhibitor. Specifically, cytoplasm-localized hRFPL1 prevented cyclin B1 and Cdc2 accumulation during interphase. Consequently, cells showed a delayed entry into mitosis and cell-cycle lengthening resulting from a threefold increase in G2 phase duration. Given previous reports that RFPL1 is expressed during cell differentiation, its impact on cell-cycle lengthening therefore provides novel insights into primate-specific development.","216593","Open Access","0.644","0.2594","4","Generating asymmetrical division, Asymmetry a wnt, Biology (general)","Generating asymmetrical division, Asymmetry a wnt, Biology (general)","5",NA,NA,"",""
"10.1093/cercor/bhp242","dedup_wf_001::cf4b1e8f7d4d6483873ab1cb1bd69ddb","Cortex","Differential Expression of LIM-Homeodomain Factors in Cajal-Retzius Cells of Primates, Rodents, and Birds","Abellan, Antonio","2010-01-01","OXFORD UNIV PRESS INC","publication","","CEREBRAL CORTEX","","Reelin-expressing Cajal-Retzius (CR) cells are among the earliest
			generated cells in the mammalian cerebral cortex and are believed
			to be crucial for both the development and the evolution of
			a laminated pattern in the pallial wall of the telencephalon. LIMhomeodomain
			(LIM-hd) transcription factors are expressed during
			brain development in a highly restricted and combinatorial manner,
			and they specify regional and cellular identity. We have investigated
			the expression of the LIM-hd members Lhx1/Lhx2/Lhx5/
			Lhx6/Lhx9 in the reelin-expressing cells, the pallium, and the
			regions of origin of CR cells including the cortical hem of 3 amniote
			species: the mouse, the chick, and the macaque monkey. We found
			major differences in the combinatorial LIM-hd expression in the
			marginal zone as well as in the hem. 1) Lhx5 is a ‘‘preferential LIMhd’’
			for CR cells in mammals but not expressed by these cells in
			chicks. 2) Lhx2 is expressed in the hem of the chick, whereas it is
			excluded from this region in mouse. 3) Whereas mouse CR cells
			express Lhx5/Lhx1, their monkey counterparts express 4 of these
			factors: Lhx1/Lhx2/Lhx5/Lhx9. We discuss our findings in evolutionary
			terms for the specification of the midline hem and CR cell type
			and the emergence of the cortical lamination pattern.
			This work was supported by Centre National de la Recherche Scientifique (CNRS), Agence Nationale pour la Recherche (ANR-Neuro [MIDLINE]) to S.R.; Agence Nationale pour la Recherche (ANR [06-NEUR-010-01]), SECO (EU FP7-216593) to C.D.; Spanish Ministry of Education and Science and FEDER (DGICYT-FEDER grant no. BFU2006-14804-C02-02/BFI) to L.M. A.M. was a postdoctoral fellow supported by CNRS.","216593","Restricted","0.499","0.3966","4","Generating asymmetrical division, Asymmetry a wnt, Biology (general)","Generating asymmetrical division, Asymmetry a wnt, Biology (general)","31",NA,NA,"",""
"10.1093/cercor/bhq201","dedup_wf_001::e896c7952d497062b5a8cceca6977e26","macaque","Weight Consistency Specifies Regularities of Macaque Cortical Networks","Markov, N. T.","2011-01-01","OXFORD UNIV PRESS INC","publication","","CEREBRAL CORTEX","","To what extent cortical pathways show significant weight differences and whether these differences are consistent across animals (thereby comprising robust connectivity profiles) is an important and unresolved neuroanatomical issue. Here we report a quantitative retrograde tracer analysis in the cynomolgus macaque monkey of the weight consistency of the afferents of cortical areas across brains via calculation of a weight index (fraction of labeled neurons, FLN). Injection in 8 cortical areas (3 occipital plus 5 in the other lobes) revealed a consistent pattern: small subcortical input (1.3% cumulative FLN), high local intrinsic connectivity (80% FLN), high-input form neighboring areas (15% cumulative FLN), and weak long-range corticocortical connectivity (3% cumulative FLN). Corticocortical FLN values of projections to areas V1, V2, and V4 showed heavy-tailed, lognormal distributions spanning 5 orders of magnitude that were consistent, demonstrating significant connectivity profiles. These results indicate that 1) connection weight heterogeneity plays an important role in determining cortical network specificity, 2) high investment in local projections highlights the importance of local processing, and 3) transmission of information across multiple hierarchy levels mainly involves pathways having low FLN values.","216593","Open Access","-0.3574","0.5546","7","[sdv.neu] life sciences [q-bio]/neurons and cognition [q-bio.nc], Cortical networks","[sdv.neu] life sciences [q-bio]/neurons and cognition [q-bio.nc], Cortical networks","118","1","281","",""
"10.1093/cercor/bhs270","dedup_wf_001::3e86e4666fcda51520608ad8d540a97a","cortex","A Weighted and Directed Interareal Connectivity Matrix for Macaque Cerebral Cortex","Markov, N. T.","2012-09-01","Oxford University Press","publication","","Cerebral Cortex (New York, NY)","","Retrograde tracer injections in 29 of the 91 areas of the macaque cerebral cortex revealed 1,615 interareal pathways, a third of which have not previously been reported. A weight index (extrinsic fraction of labeled neurons [FLNe]) was determined for each area-to-area pathway. Newly found projections were weaker on average compared with the known projections; nevertheless, the 2 sets of pathways had extensively overlapping weight distributions. Repeat injections across individuals revealed modest FLNe variability given the range of FLNe values (standard deviation <1 log unit, range 5 log units). The connectivity profile for each area conformed to a lognormal distribution, where a majority of projections are moderate or weak in strength. In the G 29 × 29 interareal subgraph, two-thirds of the connections that can exist do exist. Analysis of the smallest set of areas that collects links from all 91 nodes of the G 29 × 91 subgraph (dominating set analysis) confirms the dense (66%) structure of the cortical matrix. The G 29 × 29 subgraph suggests an unexpectedly high incidence of unidirectional links. The directed and weighted G 29 × 91 connectivity matrix for the macaque will be valuable for comparison with connectivity analyses in other species, including humans. It will also inform future modeling studies that explore the regularities of cortical networks.","5R01MH060974-17","Open Access","-0.4161","0.5233","7","[sdv.neu] life sciences [q-bio]/neurons and cognition [q-bio.nc], Cortical networks","[sdv.neu] life sciences [q-bio]/neurons and cognition [q-bio.nc], Cortical networks","162","6","351","",""
"10.1093/cercor/bhs327","dedup_wf_001::6a9ed190c389ca17cfda8a333ffb86ac","superficial patch system","Developmental Origin of Patchy Axonal Connectivity in the Neocortex: A Computational Model","Bauer, Roman","2012-11-01","Oxford University Press","publication","","Cerebral Cortex (New York, NY)","http://www.zora.uzh.ch/id/eprint/75294/1/Cereb._Cortex-2012-Bauer-cercor_bhs327.pdf","Injections of neural tracers into many mammalian neocortical areas reveal a common patchy motif of clustered axonal projections. We studied in simulation a mathematical model for neuronal development in order to investigate how this patchy connectivity could arise in layer II/III of the neocortex. In our model, individual neurons of this layer expressed the activator–inhibitor components of a Gierer–Meinhardt reaction–diffusion system. The resultant steady-state reaction–diffusion pattern across the neuronal population was approximately hexagonal. Growth cones at the tips of extending axons used the various morphogens secreted by intrapatch neurons as guidance cues to direct their growth and invoke axonal arborization, so yielding a patchy distribution of arborization across the entire layer II/III. We found that adjustment of a single parameter yields the intriguing linear relationship between average patch diameter and interpatch spacing that has been observed experimentally over many cortical areas and species. We conclude that a simple Gierer–Meinhardt system expressed by the neurons of the developing neocortex is sufficient to explain the patterns of clustered connectivity observed experimentally.","216593","Open Access","-0.4304","0.2164","1","Visual cortex, Pyramidal cells","Visual cortex, Pyramidal cells","7","1","53","",""
"10.1111/ejn.12124","webcrawl____::0f178890c8249d6cee0c09da3b8bf788","area macaque;dopaminergic innervation; fine","The fine structure of the dopaminergic innervation of area 10 of macaque prefrontal cortex","Martin, Kevan A. C.","2013-01-01","WILEY-BLACKWELL","publication","","EUROPEAN JOURNAL OF NEUROSCIENCE","","","216593","Closed Access","0.2837","0.7286","14","Dopaminergic innervation, Macaque prefrontal cortex","Dopaminergic innervation, Macaque prefrontal cortex","5","1","24","",""
"10.1126/science.1238406","dedup_wf_001::f4503b86c2078a63ac5d1ea48977e715","[SDV.NEU] Life Sciences [q-bio]/Neurons and Cognition [q-bio.NC]","Cortical high-density counterstream architectures.","Markov, Nikola,","2013-11-01","American Association for the Advancement of Science","publication","","SCIENCE","http://www.hal.inserm.fr/inserm-00879494/document","International audience; Small-world networks provide an appealing description of cortical architecture owing to their capacity for integration and segregation combined with an economy of connectivity. Previous reports of low-density interareal graphs and apparent small-world properties are challenged by data that reveal high-density cortical graphs in which economy of connections is achieved by weight heterogeneity and distance-weight correlations. These properties define a model that predicts many binary and weighted features of the cortical network including a core-periphery, a typical feature of self-organizing information processing systems. Feedback and feedforward pathways between areas exhibit a dual counterstream organization, and their integration into local circuits constrains cortical computation. Here, we propose a bow-tie representation of interareal architecture derived from the hierarchical laminar weights of pathways between the high-efficiency dense core and periphery.","216593","Open Access","-0.0949","0.5397","7","[sdv.neu] life sciences [q-bio]/neurons and cognition [q-bio.nc], Cortical networks","[sdv.neu] life sciences [q-bio]/neurons and cognition [q-bio.nc], Cortical networks","145","20","556","",""
"10.1162/neco.2009.01-09-947","dedup_wf_001::d20062dd0b69899eeb35c25de438f351","analog neurons;binary analog;computing binary","Connectivity, Dynamics, and Memory in Reservoir Computing with Binary and Analog Neurons","Buesing, Lars","2010-01-01","MIT PRESS","publication","","NEURAL COMPUTATION","","","231267","Closed Access","-0.3165","-0.5493","15","Analog neurons, Information bottleneck","Analog neurons, Information bottleneck","59",NA,NA,"",""
"10.1162/neco.2010.03-09-980","dedup_wf_001::1b672367efab642eb0209eeb2c873efc","decision making;learning decision","Reward-modulated Hebbian learning of decision making","Pfeiffer M.","2010-01-01","M I T PRESS","publication","","Neural Computation","","","231267","Closed Access","0.675","-0.3059","8","Modulated hebbian learning, Reward modulated hebbian, Decision making","Modulated hebbian learning, Reward modulated hebbian, Decision making","15",NA,NA,"",""
"10.1162/neco.2010.08-09-1084","dedup_wf_001::4ed5baf214aa8bdc2fee5de61368f394","information bottleneck;neuron information; spiking","A Spiking Neuron as Information Bottleneck","Buesing, Lars","2010-01-01","M I T PRESS","publication","","NEURAL COMPUTATION","","","231267","Closed Access","-0.253","-0.6525","15","Analog neurons, Information bottleneck","Analog neurons, Information bottleneck","8",NA,NA,"",""
"10.1162/neco_a_00050","dedup_wf_001::d07d39dafe363c00ff6cc313adf8bff6","basis emergent;discrimination neural;emergent pattern","A theoretical basis for emergent pattern discrimination in neural systems through slow feature extraction","Klampfl S.","2010-01-01","MIT PRESS","publication","","Neural Computation","","","231267","Closed Access","0.7053","-0.1302","3","Classification learning, Emergent pattern, Feature analysis","Classification learning, Emergent pattern, Feature analysis","8",NA,NA,"",""
"10.1162/neco_a_00091","dedup_wf_001::147a47be39e9866e1150d61313a23092","Quantitative Biology - Neurons and Cognition","Collective stability of networks of winner-take-all circuits","Rutishauser, Ueli","2011-05-16","MIT Press","publication","","","http://www.zora.uzh.ch/id/eprint/47178/1/Rutishause_Douglas_Slotine_Stability_of_networks.pdf","The neocortex has a remarkably uniform neuronal organization, suggesting that common principles of processing are employed throughout its extent. In particular, the patterns of connectivity observed in the superficial layers of the visual cortex are consistent with the recurrent excitation and inhibitory feedback required for cooperative-competitive circuits such as the soft winner-take-all (WTA). WTA circuits offer interesting computational properties such as selective amplification, signal restoration, and decision making. But, these properties depend on the signal gain derived from positive feedback, and so there is a critical trade-off between providing feedback strong enough to support the sophisticated computations, while maintaining overall circuit stability. We consider the question of how to reason about stability in very large distributed networks of such circuits. We approach this problem by approximating the regular cortical architecture as many interconnected cooperative-competitive modules. We demonstrate that by properly understanding the behavior of this small computational module, one can reason over the stability and convergence of very large networks composed of these modules. We obtain parameter ranges in which the WTA circuit operates in a high-gain regime, is stable, and can be aggregated arbitrarily to form large stable networks. We use nonlinear Contraction Theory to establish conditions for stability in the fully nonlinear case, and verify these solutions using numerical simulations. The derived bounds allow modes of operation in which the WTA network is multi-stable and exhibits state-dependent persistent activities. Our approach is sufficiently general to reason systematically about the stability of any network, biological or technological, composed of networks of small modules that express competition through shared inhibition.","216593","Open Access","0.1671","-0.1297","5","Computational biology, Cortex","Computational biology, Cortex","23","1","82","",""
"10.1162/neco_a_00195","webcrawl____::c5a905c34ba61bc6c5ac9a6da80fe176","bilinear networks;invariant recognition;networks invariant","Self-Organization of Topographic Bilinear Networks for Invariant Recognition","Bergmann, Urs","2011-01-01","MIT PRESS","publication","","NEURAL COMPUTATION","","","216593","Closed Access","0.544","0.4967","9","Bilinear networks, Invariant recognition, Translation invariance","Bilinear networks, Invariant recognition, Translation invariance","6",NA,NA,"",""
"10.1162/neco_a_00446","dedup_wf_001::f71327d69014f1ba75f747db27a16870","codes stdp;decoding population;emergence optimal","Emergence of optimal decoding of population codes through STDP","Habenschuss S.","2013-01-01","MIT PRESS","publication","","Neural Computation","","","216593","Closed Access","0.5744","-0.5284","14","Dopaminergic innervation, Macaque prefrontal cortex","Dopaminergic innervation, Macaque prefrontal cortex","10","3","80","",""
"10.1186/1471-2202-11-s1-p38","od_______908::f97248da9ac338ac0b5caf806cc573b5","Poster Presentation","Holistically convergent modular networks: a biological principle for recurrent network architecture","Cook, Matthew","2010-07-01","BioMed Central","publication","","BMC Neuroscience","","","216593","Open Access","0.5117","-0.0518","5","Computational biology, Cortex","Computational biology, Cortex","0",NA,NA,"",""
"10.1186/1471-2202-12-s1-p349","od_______908::8340483875fa7221ceab2c81c55ea782","Poster Presentation","The flatness of bifurcations in 3D neuronal branching patterns","van Pelt, Jaap","2011-07-01","BioMed Central","publication","","BMC Neuroscience","","","216593","Open Access","0.1077","0.6612","12","Flatness of bifurcations","Flatness of bifurcations","0",NA,NA,"",""
"10.1186/1471-2202-12-s1-p353","dedup_wf_001::459661a1e19e7566dc7fcb7f0ff28608","Neurosciences. Biological psychiatry. Neuropsychiatry","The impact of resource competition on neurite outgrowth","Hjorth, Johannes JJ","2011-07-01","BioMed Central","publication","","BMC Neuroscience","","","216593","Open Access","0.4057","-0.6682","13","Neurosciences. biological psychiatry. neuropsychiatry","Neurosciences. biological psychiatry. neuropsychiatry","0",NA,NA,"",""
"10.1186/1471-2202-12-s1-p356","dedup_wf_001::d688f58c9ebcbe9731c1fe2e62d3885c","Neurosciences. Biological psychiatry. Neuropsychiatry","Independently outgrowing neurons with a geometric synapse formation model develop realistic network connectivity patterns with small-world properties","van Ooyen Arjen","2011-07-01","BioMed Central","publication","","BMC Neuroscience","","","216593","Open Access","-0.2271","0.1885","13","Neurosciences. biological psychiatry. neuropsychiatry","Neurosciences. biological psychiatry. neuropsychiatry","0",NA,NA,"",""
"10.1242/jcs.023465","webcrawl____::7b6851d202c5605c1a204dec0f28ca3f","bigger brains;brains evolution;cell division","Making bigger brains - the evolution of neural-progenitor-cell division","Fish, Jennifer L.","2008-01-01","COMPANY OF BIOLOGISTS LTD","publication","","JOURNAL OF CELL SCIENCE","","","216593","Closed Access","0.2152","-0.7803","2","Bigger brains, Brain circuits, Cell division","Bigger brains, Brain circuits, Cell division","128","1","188","",""
"10.1371/journal.pbio.1000260","dedup_wf_001::d8e682d5b16181b914370bddeeb3ac24","Research Article","Distributed fading memory for stimulus properties in the primary visual cortex","Nikolić, Danko","2009-12-22","Public Library of Science (PLoS)","publication","","","","It is currently not known how distributed neuronal responses in early visual areas carry stimulus-related information. We made multielectrode recordings from cat primary visual cortex and applied methods from machine learning in order to analyze the temporal evolution of stimulus-related information in the spiking activity of large ensembles of around 100 neurons. We used sequences of up to three different visual stimuli (letters of the alphabet) presented for 100 ms and with intervals of 100 ms or larger. Most of the information about visual stimuli extractable by sophisticated methods of machine learning, i.e., support vector machines with nonlinear kernel functions, was also extractable by simple linear classification such as can be achieved by individual neurons. New stimuli did not erase information about previous stimuli. The responses to the most recent stimulus contained about equal amounts of information about both this and the preceding stimulus. This information was encoded both in the discharge rates (response amplitudes) of the ensemble of neurons and, when using short time constants for integration (e.g., 20 ms), in the precise timing of individual spikes (<or= approximately 20 ms), and persisted for several 100 ms beyond the offset of stimuli. The results indicate that the network from which we recorded is endowed with fading memory and is capable of performing online computations utilizing information about temporally sequential stimuli. This result challenges models assuming frame-by-frame analyses of sequential inputs.","216593","Open Access","-0.6768","-0.09","6","Primary visual cortex","Primary visual cortex","55","2","114","",""
"10.1371/journal.pcbi.1002211","dedup_wf_001::da16cc4bcf28762ebfb6dfa35e39c330","Research Article","Neural Dynamics as Sampling: A Model for Stochastic Computation in Recurrent Networks of Spiking Neurons","Buesing, Lars","2011-01-01","PUBLIC LIBRARY SCIENCE","publication","","PLOS COMPUTATIONAL BIOLOGY","","The organization of computations in networks of spiking neurons in the brain is still largely unknown, in particular in view of the inherently stochastic features of their firing activity and the experimentally observed trial-to-trial variability of neural systems in the brain. In principle there exists a powerful computational framework for stochastic computations, probabilistic inference by sampling, which can explain a large number of macroscopic experimental data in neuroscience and cognitive science. But it has turned out to be surprisingly difficult to create a link between these abstract models for stochastic computations and more detailed models of the dynamics of networks of spiking neurons. Here we create such a link and show that under some conditions the stochastic firing activity of networks of spiking neurons can be interpreted as probabilistic inference via Markov chain Monte Carlo (MCMC) sampling. Since common methods for MCMC sampling in distributed systems, such as Gibbs sampling, are inconsistent with the dynamics of spiking neurons, we introduce a different approach based on non-reversible Markov chains that is able to reflect inherent temporal processes of spiking neuronal activity through a suitable choice of random variables. We propose a neural network model and show by a rigorous theoretical analysis that its neural activity implements MCMC sampling of a given distribution, both for the case of discrete and continuous time. This provides a step towards closing the gap between abstract functional models of cortical computation and more detailed models of networks of spiking neurons.","269921","Open Access","-0.1215","-0.2803","10","Spiking neurons, Computation in recurrent, Detect hidden","Spiking neurons, Computation in recurrent, Detect hidden","90","16","345","",""
"10.1371/journal.pcbi.1003037","dedup_wf_001::7b9883befbc645a0108e79e7d11cdaf0","Computational Biology","Neural Dynamics as Sampling: A Model for Stochastic Computation in Recurrent Networks of Spiking Neurons","Nessler, Bernhard","2013-04-01","Public Library of Science","publication","","PLoS Computational Biology","http://www.zora.uzh.ch/id/eprint/91174/1/Nessler_et_al_Bayesian_computation.pdf","The principles by which networks of neurons compute, and how spike-timing dependent plasticity (STDP) of synaptic weights generates and maintains their computational function, are unknown. Preceding work has shown that soft winner-take-all (WTA) circuits, where pyramidal neurons inhibit each other via interneurons, are a common motif of cortical microcircuits. We show through theoretical analysis and computer simulations that Bayesian computation is induced in these network motifs through STDP in combination with activity-dependent changes in the excitability of neurons. The fundamental components of this emergent Bayesian computation are priors that result from adaptation of neuronal excitability and implicit generative models for hidden causes that are created in the synaptic weights through STDP. In fact, a surprising result is that STDP is able to approximate a powerful principle for fitting such implicit generative models to high-dimensional spike inputs: Expectation Maximization. Our results suggest that the experimentally observed spontaneous activity and trial-to-trial variability of cortical neurons are essential features of their information processing capability, since their functional role is to represent probability distributions rather than static neural codes. Furthermore it suggests networks of Bayesian computation modules as a new model for distributed information processing in the cortex.","243914","Open Access","-0.1948","-0.1929","10","Spiking neurons, Computation in recurrent, Detect hidden","Spiking neurons, Computation in recurrent, Detect hidden","80","28","374","",""
"10.1371/journal.pcbi.1003173","dedup_wf_001::1b566842d34c60de4c8f773684c165bd","Computational Biology","Simulating Cortical Development as a Self Constructing Process: A Novel Multi-Scale Approach Combining Molecular and Physical Aspects","Zubler, Frederic","2013-08-01","Public Library of Science","publication","","PLoS Computational Biology","http://www.zora.uzh.ch/id/eprint/91200/1/journal.pcbi.1003173.pdf","Current models of embryological development focus on intracellular processes such as gene expression and protein networks, rather than on the complex relationship between subcellular processes and the collective cellular organization these processes support. We have explored this collective behavior in the context of neocortical development, by modeling the expansion of a small number of progenitor cells into a laminated cortex with layer and cell type specific projections. The developmental process is steered by a formal language analogous to genomic instructions, and takes place in a physically realistic three-dimensional environment. A common genome inserted into individual cells control their individual behaviors, and thereby gives rise to collective developmental sequences in a biologically plausible manner. The simulation begins with a single progenitor cell containing the artificial genome. This progenitor then gives rise through a lineage of offspring to distinct populations of neuronal precursors that migrate to form the cortical laminae. The precursors differentiate by extending dendrites and axons, which reproduce the experimentally determined branching patterns of a number of different neuronal cell types observed in the cat visual cortex. This result is the first comprehensive demonstration of the principles of self-construction whereby the cortical architecture develops. In addition, our model makes several testable predictions concerning cell migration and branching mechanisms.","216593","Open Access","0.2076","0.1762","5","Computational biology, Cortex","Computational biology, Cortex","13","8","67","",""
"10.1371/journal.pcbi.1003994","dedup_wf_001::2ffb18979d92b5f0ab3fcb9db7f7b7f4","Computational Biology","Developmental Self-Construction and -Configuration of Functional Neocortical Neuronal Networks","Bauer, Roman","2014-12-01","Public Library of Science","publication","","PLoS Computational Biology","http://boris.unibe.ch/63630/1/Bauer14_PloSCompBioll.pdf","Author Summary Models of learning in artificial neural networks generally assume that the neurons and approximate network are given, and then learning tunes the synaptic weights. By contrast, we address the question of how an entire functional neuronal network containing many differentiated neurons and connections can develop from only a single progenitor cell. We chose a winner-take-all network as the developmental target, because it is a computationally powerful circuit, and a candidate motif of neocortical networks. The key aspect of this challenge is that the developmental mechanisms must be locally autonomous as in Biology: They cannot depend on global knowledge or supervision. We have explored this developmental process by simulating in physical detail the fundamental biological behaviors, such as cell proliferation, neurite growth and synapse formation that give rise to the structural connectivity observed in the superficial layers of the neocortex. These differentiated, approximately connected neurons then adapt their synaptic weights homeostatically to obtain a uniform electrical signaling activity before going on to organize themselves according to the fundamental correlations embedded in a noisy wave-like input signal. In this way the precursor expands itself through development and unsupervised learning into winner-take-all functionality and orientation selectivity in a biologically plausible manner.","216593","Open Access","-0.0576","-0.0675","5","Computational biology, Cortex","Computational biology, Cortex","8","5","48","",""
"10.1371/journal.pcbi.1004039","dedup_wf_001::f12eae7307cb0059d66326312ffa7b6a","Research Article","Computation in Dynamically Bounded Asymmetric Systems","Rutishauser, Ueli","2015-01-01","Public Library of Science","publication","","PLoS Computational Biology","https://authors.library.caltech.edu/54075/1/Rutishauser2015_CB.pdf","Author Summary Biological systems are obviously able to process abstract information on the states of neuronal and molecular networks. However, the concepts and principles of such biological computation are poorly understood by comparison with technological computing. A key concept in models of biological computation has been the attractor of dynamical systems, and much progress has been made in describing the conditions under which attractors exist, and their stability. Instead, we show here for a broad class of asymmetrically connected networks that it is the unstable dynamics of the system that drive its computation, and we develop new analytical tools to describe the kinds of unstable dynamics that support this computation in our model. In particular we explore the conditions under which networks will exhibit unstable expansion of their dynamics, and how these can be steered and constrained so that the trajectory implements a specific computation. Importantly, the underlying computational elements of the network are not themselves stable. Instead, the overall boundedness of the system is provided by the asymmetrical coupling between excitatory and inhibitory elements commonly observed in neuronal and molecular networks. This inherent boundedness permits the network to operate with the unstably high gain necessary to continually switch its states as it searches for a solution. We propose that very simple organizational constraints can lead to spontaneous computation, and thereby to the spontaneous modification of entropy that is characteristic of living systems.","216593","Open Access","0.0197","-0.2821","10","Spiking neurons, Computation in recurrent, Detect hidden","Spiking neurons, Computation in recurrent, Detect hidden","2",NA,"47","",""
"10.1371/journal.pone.0050189","dedup_wf_001::92e6d02eb8124420c549549aab36ebce","Cellular Types","Short term depression unmasks the ghost frequency.","Tjeerd V Olde Scheper","","Public Library of Science (PLoS)","publication","","PLoS ONE","https://research.vu.nl/ws/files/679073/295614.pdf","Short Term Plasticity (STP) has been shown to exist extensively in synapses throughout the brain. Its function is more or less clear in the sense that it alters the probability of synaptic transmission at short time scales. However, it is still unclear what effect STP has on the dynamics of neural networks. We show, using a novel dynamic STP model, that Short Term Depression (STD) can affect the phase of frequency coded input such that small networks can perform temporal signal summation and determination with high accuracy. We show that this property of STD can readily solve the problem of the ghost frequency, the perceived pitch of a harmonic complex in absence of the base frequency. Additionally, we demonstrate that this property can explain dynamics in larger networks. By means of two models, one of chopper neurons in the Ventral Cochlear Nucleus and one of a cortical microcircuit with inhibitory Martinotti neurons, it is shown that the dynamics in these microcircuits can reliably be reproduced using STP. Our model of STP gives important insights into the potential roles of STP in self-regulation of cortical activity and long-range afferent input in neuronal microcircuits. © 2012 olde Scheper et al.","216593","Open Access","-0.1605","0.0293","10","Spiking neurons, Computation in recurrent, Detect hidden","Spiking neurons, Computation in recurrent, Detect hidden","1","1","10","",""
"10.1371/journal.pone.0071615","dedup_wf_001::9c1edc992b6f24b1e0043dee7f074ac2","Computational Biology","Decoding the Dopamine Signal in Macaque Prefrontal Cortex: A Simulation Study Using the Cx3Dp Simulator","Spuehler, Isabelle Ayumi","2013-01-01","PUBLIC LIBRARY SCIENCE","publication","","PLOS ONE","http://www.zora.uzh.ch/id/eprint/91189/1/journal.pone.0071615.pdf","Dopamine transmission in the prefrontal cortex plays an important role in reward based learning, working memory and attention. Dopamine is thought to be released non-synaptically into the extracellular space and to reach distant receptors through diffusion. This simulation study examines how the dopamine signal might be decoded by the recipient neuron. The simulation was based on parameters from the literature and on our own quantified, structural data from macaque prefrontal area 10. The change in extracellular dopamine concentration was estimated at different distances from release sites and related to the affinity of the dopamine receptors. Due to the sparse and random distribution of release sites, a transient heterogeneous pattern of dopamine concentration emerges. Our simulation predicts, however, that at any point in the simulation volume there is sufficient dopamine to bind and activate high-affinity dopamine receptors. We propose that dopamine is broadcast to its distant receptors and any change from the local baseline concentration might be decoded by a transient change in the binding probability of dopamine receptors. Dopamine could thus provide a graduated 'teaching' signal to reinforce concurrently active synapses and cell assemblies. In conditions of highly reduced or highly elevated dopamine levels the simulations predict that relative changes in the dopamine signal can no longer be decoded, which might explain why cognitive deficits are observed in patients with Parkinson's disease, or induced through drugs blocking dopamine reuptake.","216593","Open Access","-0.6272","0.4268","14","Dopaminergic innervation, Macaque prefrontal cortex","Dopaminergic innervation, Macaque prefrontal cortex","3",NA,"12","",""
"10.1371/journal.pone.0085858","dedup_wf_001::5cf178634a9796fb73735caf31551b93","Computational Biology","Independently Outgrowing Neurons and Geometry-Based Synapse Formation Produce Networks with Realistic Synaptic Connectivity","van Ooyen, Arjen","2014-01-01","Public Library of Science","publication","","PLoS ONE","","Neuronal signal integration and information processing in cortical networks critically depend on the organization of synaptic connectivity. During development, neurons can form synaptic connections when their axonal and dendritic arborizations come within close proximity of each other. Although many signaling cues are thought to be involved in guiding neuronal extensions, the extent to which accidental appositions between axons and dendrites can already account for synaptic connectivity remains unclear. To investigate this, we generated a local network of cortical L2/3 neurons that grew out independently of each other and that were not guided by any extracellular cues. Synapses were formed when axonal and dendritic branches came by chance within a threshold distance of each other. Despite the absence of guidance cues, we found that the emerging synaptic connectivity showed a good agreement with available experimental data on spatial locations of synapses on dendrites and axons, number of synapses by which neurons are connected, connection probability between neurons, distance between connected neurons, and pattern of synaptic connectivity. The connectivity pattern had a small-world topology but was not scale free. Together, our results suggest that baseline synaptic connectivity in local cortical circuits may largely result from accidentally overlapping axonal and dendritic branches of independently outgrowing neurons.","281443","Open Access","-0.3872","0.0495","1","Visual cortex, Pyramidal cells","Visual cortex, Pyramidal cells","13","1","41","",""
"10.1523/jneurosci.4071-12.2013","dedup_wf_001::7ed6bf76ee0fea8c9b8b44b6c4454071","Institute of Neuroinformatics","Functional heterogeneity in neighboring neurons of cat primary visual cortex in response to both artificial and natural stimuli","Martin, Kevan A C","2013-01-01","Society for Neuroscience","publication","","","http://www.zora.uzh.ch/id/eprint/91164/1/Martin_Schroeder_Functional_heterogeneity.pdf","Neurons in primary visual cortex of many mammals are clustered according to their preference to stimulus parameters such as orientation and spatial frequency. Nevertheless, responses to complex visual stimuli are highly heterogeneous between adjacent neurons. To investigate the relation between these observations, we recorded from pairs of neighboring neurons in area 17 of anesthetized cats in response to stimuli of differing complexity: sinusoidal drifting gratings, binary dense noise, and natural movies. Comparisons of the tuning curves revealed similar orientation and direction preferences for neighboring neurons, but large differences in preferred phase, direction selectivity, and tuning width of spatial frequency. No pair was similar across all tuning properties. The neurons' firing rates averaged across multiple stimulus repetitions (the “signal”) were also compared. Binned between 10 and 200 ms, the correlation between these signals was close to zero in the median across all pairs for all stimulus classes. Signal correlations agreed poorly with differences in tuning properties, except for receptive field offset and relative modulation (i.e., the strength of phase modulation). Nonetheless, signal correlations for different stimulus classes were well correlated with each other, even for gratings and movies. Conversely, trial-to-trial fluctuations (termed “noise”) were poorly correlated between neighboring neurons, suggesting low degrees of common input. In response to gratings and visual noise, signal and noise correlations were well correlated with each other, but less so for responses to movies. These findings have relevance for our understanding of the processing of natural stimuli in a functionally heterogeneous cortical network.","216593","Open Access","-0.6741","0.0713","6","Primary visual cortex","Primary visual cortex","27",NA,NA,"",""
"10.1523/jneurosci.4284-09.2010","dedup_wf_001::06010e68e1c8361bc5dda92a12fce964","Quantitative Biology::Neurons and Cognition","A reward-modulated Hebbian learning rule can explain experimentally observed network reorganization in a brain control task","Legenstein R.","2010-01-01","SOC NEUROSCIENCE","publication","","Journal of Neuroscience","","It has recently been shown in a brain-computer interface experiment that motor cortical neurons change their tuning properties selectively to compensate for errors induced by displaced decoding parameters. In particular, it was shown that the 3D tuning curves of neurons whose decoding parameters were re-assigned changed more than those of neurons whose decoding parameters had not been re-assigned. In this article, we propose a simple learning rule that can reproduce this effect. Our learning rule uses Hebbian weight updates driven by a global reward signal and neuronal noise. In contrast to most previously proposed learning rules, this approach does not require extrinsic information to separate noise from signal. The learning rule is able to optimize the performance of a model system within biologically realistic periods of time under high noise levels. Furthermore, when the model parameters are matched to data recorded during the brain-computer interface learning experiments described above, the model produces learning effects strikingly similar to those found in the experiments.","1R01NS050256-01A2","Open Access","0.0256","-0.4892","8","Modulated hebbian learning, Reward modulated hebbian, Decision making","Modulated hebbian learning, Reward modulated hebbian, Decision making","51",NA,NA,"",""
"10.1523/jneurosci.5684-10.2011","dedup_wf_001::ae1c69e86aeaa4127d10c9e88e6ac2d5","dendritic;nonlinear;plasticity","Branch-Specific Plasticity Enables Self-Organization of Nonlinear Computation in Single Neurons","Legenstein, Robert","2011-01-01","SOC NEUROSCIENCE","publication","","JOURNAL OF NEUROSCIENCE","","It has been conjectured that nonlinear processing in dendritic branches endows individual neurons with the capability to perform complex computational operations that are needed in order to solve for example the binding problem. However, it is not clear how single neurons could acquire such functionality in a self-organized manner, since most theoretical studies of synaptic plasticity and learning concentrate on neuron models without nonlinear dendritic properties. In the meantime, a complex picture of information processing with dendritic spikes and a variety of plasticity mechanisms in single neurons has emerged from experiments. In particular, new experimental data on dendritic branch strength potentiation in rat hippocampus have not yet been incorporated into such models. In this article, we investigate how experimentally observed plasticity mechanisms, such as depolarization-dependent STDP and branch-strength potentiation could be integrated to self-organize nonlinear neural computations with dendritic spikes. We provide a mathematical proof that in a simplified setup these plasticity mechanisms induce a competition between dendritic branches, a novel concept in the analysis of single neuron adaptivity. We show via computer simulations that such dendritic competition enables a single neuron to become member of several neuronal ensembles, and to acquire nonlinear computational capabilities, such as for example the capability to bind multiple input features. Hence our results suggest that nonlinear neural computation may self-organize in single neurons through the interaction of local synaptic and dendritic plasticity mechanisms.","216593","Open Access","-0.3669","-0.264","10","Spiking neurons, Computation in recurrent, Detect hidden","Spiking neurons, Computation in recurrent, Detect hidden","48","2","174","",""
"10.3389/fncom.2010.00148","dedup_wf_001::4cb07aa31180a3f985e7ba6f3a099eb5","line crossing","An Algorithm for Finding Candidate Synaptic Sites in Computer Generated Networks of Neurons with Realistic Morphologies","van Pelt, Jaap","2010-11-29","Frontiers Research Foundation","publication","","Frontiers in Computational Neuroscience","","Neurons make synaptic connections at locations where axons and dendrites are sufficient close in space. Typically the required proximity is based on the dimensions of dendritic spines and axonal boutons. Based on this principle one can search those locations in networks formed by reconstructed neurons or computer generated neurons. Candidate synapses are then located where axons and dendrites are within a given criterion distance from each other. Both experimentally reconstructed and model generated neurons are usually represented morphologically by piece wise linear structures (line pieces or cylinders). Proximity tests are then to be performed on all pairs of line pieces from both axonal and dendritic branches. Applying just a test on the distance between line pieces may result in local clusters of synaptic sites when more than one pair of nearby line pieces from axonal and dendritic branches is sufficient close, and may introduce a dependency on the length scale of the individual line pieces. The present paper describes a new algorithm for defining locations of candidate synapses which is based on the crossing requirement of a line piece pair, while the length of the orthogonal distance between the line pieces is subjected to the distance criterion for testing 3D proximity","2300150068","Open Access","-0.5884","-0.1794","1","Visual cortex, Pyramidal cells","Visual cortex, Pyramidal cells","6",NA,NA,"",""
"10.3389/fncom.2011.00054/full","dedup_wf_001::8ce269c31a71db6729aa63e6f7ecb51e","trihedral angle","The Flatness of Bifurcations in 3D Dendritic Trees: An Optimal Design","van Pelt, Jaap","2012-01-01","Frontiers Research Foundation","publication","","Frontiers in Computational Neuroscience","","
			The geometry of natural branching systems generally reflects functional optimization. A common property is that their bifurcations are planar and that daughter segments do not turn back in the direction of the parent segment. The present study investigates whether this also applies to bifurcations in 3D dendritic arborizations. This question was earlier addressed in a first study of flatness of 3D dendritic bifurcations by Uylings and Smit (1975), who used the apex angle of the right circular cone as flatness measure. The present study was inspired by recent renewed interest in this measure. Because we encountered ourselves shortcomings of this cone angle measure, the search for an optimal measure for flatness of 3D bifurcation was the second aim of our study. Therefore, a number of measures has been developed in order to quantify flatness and orientation properties of spatial bifurcations. All these measures have been expressed mathematically in terms of the three bifurcation angles between the three pairs of segments in the bifurcation. The flatness measures have been applied and evaluated to bifurcations in rat cortical pyramidal cell basal and apical dendritic trees, and to random spatial bifurcations. Dendritic and random bifurcations show significant different flatness measure distributions, supporting the conclusion that dendritic bifurcations are significantly more flat than random bifurcations. Basal dendritic bifurcations also show the property that their parent segments are generally aligned oppositely to the bisector of the angle between their daughter segments, resulting in “symmetrical” configurations. Such geometries may arise when during neuronal development the segments at a newly formed bifurcation are subjected to elastic tensions, which force the bifurcation into an equilibrium planar shape. Apical bifurcations, however, have parent segments oppositely aligned with one of the daughter segments. These geometries arise in the case of side branching from an existing apical main stem. The aligned “apical” parent and “apical” daughter segment form together with the side branch daughter segment already geometrically a flat configuration. These properties are clearly reflected in the flatness measure distributions. Comparison of the different flatness measures made clear that they all capture flatness properties in a different way. Selection of the most appropriate measure thus depends on the question of research. For our purpose of quantifying flatness and orientation of the segments, the dihedral angle β was found to be the most discriminative and applicable single measure. Alternatively, the parent elevation and azimuth angle formed an orthogonal pair of measures most clearly demonstrating the dendritic bifurcation “symmetry” properties.
			","2300150068","Open Access","0.0261","0.7733","12","Flatness of bifurcations","Flatness of bifurcations","",NA,NA,"",""
"10.3389/fncom.2011.00057/full","dedup_wf_001::d89b2b45bd054635f2b5c5dc3de18ebf","cortex","An Instruction Language for Self-Construction in the Context of Neural Networks","Zubler, Frederic","2011-12-01","Frontiers Research Foundation","publication","","Frontiers in Computational Neuroscience","http://www.zora.uzh.ch/id/eprint/60632/1/Instruction_language.pdf","
			Biological systems are based on an entirely different concept of construction than human artifacts. They construct themselves by a process of self-organization that is a systematic spatio-temporal generation of, and interaction between, various specialized cell types. We propose a framework for designing gene-like codes for guiding the self-construction of neural networks. The description of neural development is formalized by defining a set of primitive actions taken locally by neural precursors during corticogenesis. These primitives can be combined into networks of instructions similar to biochemical pathways, capable of reproducing complex developmental sequences in a biologically plausible way. Moreover, the conditional activation and deactivation of these instruction networks can also be controlled by these primitives, allowing for the design of a “genetic code” containing both coding and regulating elements. We demonstrate in a simulation of physical cell development how this code can be incorporated into a single progenitor, which then by replication and differentiation, reproduces important aspects of corticogenesis.
			","216593","Open Access","0.37","0.03","5","Computational biology, Cortex","Computational biology, Cortex","",NA,NA,"",""
"10.3389/neuro.10.025.2009/full","dedup_wf_001::cc473e9eb510a42ee1e3fc68a6c0fbcd","cortex","A Framework for Modeling the Growth and Development of Neurons and Networks","Zubler, Frederic","2009-11-01","Frontiers Research Foundation","publication","","Frontiers in Computational Neuroscience","http://www.zora.uzh.ch/id/eprint/32064/1/Zubler_FrontiersCompNeuroscience_2009_V.pdf","The development of neural tissue is a complex organizing process, in which it is difficult to grasp how the various localized interactions between dividing cells leads relentlessly to global network organization.  Simulation is a useful tool for exploring such complex processes because it permits rigorous analysis of  observed global behavior in terms of the mechanistic axioms declared in the simulated model.  We describe a novel simulation tool, CX3D, for modeling the development of large realistic neural networks such as the neocortex, in a physical 3D space. In CX3D, as in biology, neurons arise by the replication and migration of precursors, which mature into cells able to extend axons and dendrites. Individual neurons are discretized into spherical (for the soma) and cylindrical (for neurites) elements that have appropriate mechanical properties. The growth functions of each neuron are encapsulated in set of pre-defined modules that are automatically distributed across its segments during growth. The extracellular space is also discretized, and allows for the diffusion of extracellular signaling molecules, as well as the physical interactions of the many developing neurons.  We demonstrate the utility of CX3D by simulating three interesting developmental processes: neocortical lamination based on mechanical properties of tissues; a growth model of a neocortical pyramidal cell based on layer-specific guidance cues; and the formation of a neural network in vitro by employing neurite fasciculation. We also provide some examples in which previous models from the literature are re-implemented in CX3D. Our results suggest that CX3D is a powerful tool for understanding neural development.","216593","Open Access","0.0637","0.0387","5","Computational biology, Cortex","Computational biology, Cortex","",NA,NA,"",""
"10.3389/neuro.11.011.2009","dedup_wf_001::d9598815321e20113e097e305737100e","Boost.Python","PCSIM: A Parallel Simulation Environment for Neural Circuits Fully Integrated with Python","Pecevski, Dejan","2009-05-01","Frontiers Research Foundation","publication","","Frontiers in Neuroinformatics","","The Parallel Circuit SIMulator (PCSIM) is a software package for simulation of neural circuits. It is primarily designed for distributed simulation of large scale networks of spiking point neurons. Although its computational core is written in C++, PCSIM's primary interface   is implemented in the Python programming language, which is a powerful programming   environment and allows the user to easily integrate the neural circuit   simulator with data analysis and visualization tools to manage the full   neural modeling life cycle. The main focus of this paper is to describe   PCSIM's full integration into Python and the benefits thereof. In particular we will investigate how the automatically generated bidirectional interface   and PCSIM's object-oriented modular framework enable the user to adopt a   hybrid modeling approach: using and extending PCSIM's functionality either   employing pure Python or C++ and thus combining the advantages of both   worlds. Furthermore, we describe several supplementary PCSIM packages written   in pure Python and tailored towards setting up and analyzing neural   simulations.","216593","Open Access","0.4154","-0.2716","3","Classification learning, Emergent pattern, Feature analysis","Classification learning, Emergent pattern, Feature analysis","21",NA,NA,"",""
"10.5167/uzh-107823","dedup_wf_001::fa1c06e4a6f8c54dac9f9535dd34fb71","Institute of Neuroinformatics","Superficial layer pyramidal cells communicate heterogeneously between multiple functional domains of cat primary visual cortex","Martin, K A","2014-01-01","Nature Publishing Group","publication","","","http://www.zora.uzh.ch/id/eprint/107823/1/ncomms6252.pdf","The axons of pyramidal neurons in the superficial layers of the neocortex of higher mammals form lateral networks of discrete clusters of synaptic boutons. In primary visual cortex the clusters are reported to link domains that share the same orientation preferences, but how individual neurons contribute to this network is unknown. Here we performed optical imaging to record the intrinsic signal, which is an indirect measure of neuronal firing, and determined the global map of orientation preferences in the cat primary visual system. In the same experiment, single cells were recorded and labelled intracellularly. We found that individual axons arborise within the retinotopic representation of the classical receptive field, but their bouton clusters were not aligned along their preferred axis of orientation along the retinotopic map. Axon clusters formed in a variety of different orientation domains, not just the like-orientation domains. This topography and heterogeneity of single-cell connectivity provides circuits for normalization and context-dependent feature processing of visual scenes.","216593","Open Access","-0.6072","0.2111","1","Visual cortex, Pyramidal cells","Visual cortex, Pyramidal cells","",NA,NA,"",""
"10.5167/uzh-47193","dedup_wf_001::a466f31e662b0c30fd0bb9a44a98874b","Research Article","An integrated micro- and macroarchitectural analysis of the Drosophila brain by computer-assisted serial section electron microscopy.","Albert Cardona","2010-10-01","Public Library of Science (PLoS)","publication","","PLoS Biology ","http://www.zora.uzh.ch/id/eprint/47193/1/Cardona_et_al_PLoS_Biology.pdf","The analysis of microcircuitry (the connectivity at the level of individual neuronal processes and synapses), which is indispensable for our understanding of brain function, is based on serial transmission electron microscopy (TEM) or one of its modern variants. Due to technical limitations, most previous studies that used serial TEM recorded relatively small stacks of individual neurons. As a result, our knowledge of microcircuitry in any nervous system is very limited. We applied the software package TrakEM2 to reconstruct neuronal microcircuitry from TEM sections of a small brain, the early larval brain of Drosophila melanogaster. TrakEM2 enables us to embed the analysis of the TEM image volumes at the microcircuit level into a light microscopically derived neuro-anatomical framework, by registering confocal stacks containing sparsely labeled neural structures with the TEM image volume. We imaged two sets of serial TEM sections of the Drosophila first instar larval brain neuropile and one ventral nerve cord segment, and here report our first results pertaining to Drosophila brain microcircuitry. Terminal neurites fall into a small number of generic classes termed globular, varicose, axiform, and dendritiform. Globular and varicose neurites have large diameter segments that carry almost exclusively presynaptic sites. Dendritiform neurites are thin, highly branched processes that are almost exclusively postsynaptic. Due to the high branching density of dendritiform fibers and the fact that synapses are polyadic, neurites are highly interconnected even within small neuropile volumes. We describe the network motifs most frequently encountered in the Drosophila neuropile. Our study introduces an approach towards a comprehensive anatomical reconstruction of neuronal microcircuitry and delivers microcircuitry comparisons between vertebrate and insect neuropile.","216593","Open Access","0.2285","0.4266","2","Bigger brains, Brain circuits, Cell division","Bigger brains, Brain circuits, Cell division","",NA,NA,"",""
"10.5167/uzh-60639","od_______885::767002f235f57d58987f40d23c628658","Neuron Doctrine;Law of Dynamic Polarisation;Golgi stain;Canonical cortical circuits;High-throughput circuit reconstruction","What’s black and white about the grey matter?","Douglas, R J","2011-09-01","Springer","publication","","","http://www.zora.uzh.ch/id/eprint/60639/1/BandWrev26Jan2011.pdf","In 1873 Camillo Golgi discovered his eponymous stain, which he called la reazione nera. By adding to it the concepts of the Neuron Doctrine and the Law of Dynamic Polarisation, Santiago Ramon y Cajal was able to link the individual Golgi-stained neurons he saw down his microscope into circuits. This was revolutionary and we have all followed Cajal's winning strategy for over a century. We are now on the verge of a new revolution, which offers the prize of a far more comprehensive description of neural circuits and their operation. The hope is that we will exploit the power of computer vision algorithms and modern molecular biological techniques to acquire rapidly reconstructions of single neurons and synaptic circuits, and to control the function of selected types of neurons. Only one item is now conspicuous by its absence: the 21st century equivalent of the concepts of the Neuron Doctrine and the Law of Dynamic Polarisation. Without their equivalent we will inevitably struggle to make sense of our 21st century observations within the 19th and 20th century conceptual framework we have inherited.","216593","Open Access","-0.2893","-0.443","10","Spiking neurons, Computation in recurrent, Detect hidden","Spiking neurons, Computation in recurrent, Detect hidden","",NA,NA,"",""
"10.5167/uzh-75347","dedup_wf_001::0fce36f63e5eed5aadd8f8492a91ce71","Single Neuron Function","Fast Recruitment of Recurrent Inhibition in the Cat Visual Cortex","Ohana, Ora","2012-07-01","Public Library of Science","publication","","PLoS ONE","http://www.zora.uzh.ch/id/eprint/75347/1/journal.pone.0040601.pdf","Neurons of the same column in L4 of the cat visual cortex are likely to share the same sensory input from the same region of the visual field. Using visually-guided patch clamp recordings we investigated the biophysical properties of the synapses of neighboring layer 4 neurons. We recorded synaptic connections between all types of excitatory and inhibitory neurons in L4. The E–E, E–I, and I–E connections had moderate CVs and failure rates. However, E–I connections had larger amplitudes, faster rise-times, and shorter latencies. Identification of the sites of putative synaptic contacts together with compartmental simulations on 3D reconstructed cells, suggested that E–I synapses tended to be located on proximal dendritic branches, which would explain their larger EPSP amplitudes and faster kinetics. Excitatory and inhibitory synapses were located at the same distance on distal dendrites of excitatory neurons. We hypothesize that this co-localization and the fast recruitment of local inhibition provides an efficient means of modulating excitation in a precisely timed way.","216593","Open Access","-0.5358","-0.0498","1","Visual cortex, Pyramidal cells","Visual cortex, Pyramidal cells","",NA,NA,"",""
"10.7554/elife.21589","dedup_wf_001::fb435357e4cb1d9aabf0326e2863e095","visual attention","Stimulus relevance modulates contrast adaptation in visual cortex.","Keller Andreas J","2017-01-01","","publication","","eLife","http://www.zora.uzh.ch/id/eprint/134127/1/e21589-download.pdf","A general principle of sensory processing is that neurons adapt to sustained stimuli by reducing their response over time. Most of our knowledge on adaptation in single cells is based on experiments in anesthetized animals. How responses adapt in awake animals, when stimuli may be behaviorally relevant or not, remains unclear. Here we show that contrast adaptation in mouse primary visual cortex depends on the behavioral relevance of the stimulus. Cells that adapted to contrast under anesthesia maintained or even increased their activity in awake na?ve mice. When engaged in a visually guided task, contrast adaptation re-occurred for stimuli that were irrelevant for solving the task. However, contrast adaptation was reversed when stimuli acquired behavioral relevance. Regulation of cortical adaptation by task demand may allow dynamic control of sensory-evoked signal flow in the neocortex. DOI: http://dx.doi.org/10.7554/eLife.21589.001","616509","Open Access","0.351","0.5643","6","Primary visual cortex","Primary visual cortex","2","3","90","",""
