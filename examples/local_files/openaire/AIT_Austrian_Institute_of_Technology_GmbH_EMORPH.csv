"doi","id","subject","title","authors","year","publisher","resulttype","language","journal","url","paper_abstract","project_id","accessright","x","y","area_uri","cluster_labels","area","cited_by_tweeters_count","readers.mendeley","citation_count","readers","file_hash"
"10.1016/j.neunet.2011.11.001","ec_fp7_ict__::5549af26f7aefc94179eacc21b2a348f","asynchronous frameless;based optical;event based","Asynchronous frameless event-based optical flow","Benosman R.","2012-01-01","","publication","","Neural Networks","","","231467","Closed Access","-0.4785","-0.4936","9","Asynchronous frameless, Based optical, Event based","Asynchronous frameless, Based optical, Event based","3","108","45","",""
"10.1016/j.procs.2011.09.027","dedup_wf_001::0c261e7feec4f6b07a2459cab4bf961c","emorph neuromorphic;neuromorphic robotic;robotic vision","EMorph: Towards neuromorphic robotic vision","Bartolozzi C.","2011-01-01","Elsevier BV","publication","","Procedia Computer Science","","","231467","Open Access","0.4418","0.4898","5","Emorph neuromorphic, Neuromorphic robotic, Robotic vision","Emorph neuromorphic, Neuromorphic robotic, Robotic vision","2","27","3","",""
"10.1109/biocas.2009.5372048","dedup_wf_001::12695306c3f4570810b9fd34a745b384","Institute of Neuroinformatics","Applying neuromorphic vision sensors to planetary landing tasks","Orchard G.","2009-01-01","","publication","","","http://www.zora.uzh.ch/id/eprint/32034/1/biocas09.pdf","Recently there has been an increasing interest in application of bio-mimetic controller s and neuromorphic vision sensor s to planetary landing tasks. Within this context, we present combined low-level (SPICE) and high-level (behavioral) simulations of a novel neuromorphic VLSI vision sensor in a realistic planetary landing scenar io. We use results from low
			level simulations to build an abstr act descr iption of the chip which can be used in higher level simulations which include closed-loop control of the cr aft.","231467","Open Access","0.1095","0.6803","6","Institute of neuroinformatics","Institute of neuroinformatics",NA,NA,"2","",""
"10.1109/biocas.2010.5709619","ec_fp7_ict__::0d71844364b80c8a7f56c6cb1b563214","biomimetic frame;camera event;custom address","Biomimetic frame-free HDR camera with event-driven PWM image/video sensor and full-custom address-event processor","Posch C.","2010-01-01","","publication","","","","","231467","Closed Access","0.2826","-0.6143","4","Ae processor, Atis camera, Biomimetic frame","Ae processor, Atis camera, Biomimetic frame",NA,NA,"3","",""
"10.1109/biocas.2011.6107781","ec_fp7_ict__::8285e4b65e48f833e3829a25d4f75eca","access memory;asynchronous static;network spiking","A VLSI network of spiking neurons with an asynchronous static random access memory","Moradi S.","2011-01-01","","publication","","","","","231467","Closed Access","-0.6375","-0.1661","2","Access memory, Asynchronous static, Network spiking","Access memory, Asynchronous static, Network spiking",NA,NA,"7","",""
"10.1109/cvprw.2012.6238898","ec_fp7_ict__::901955962d6b469a3a48d069c232cec3","driven embodied;embodied system;extraction object","Event-driven embodied system for feature extraction and object recognition in robotic applications","Wiesmann G.","2012-01-01","","publication","","","","","231467","Closed Access","0.6162","-0.0424","10","Driven embodied, Embodied system, Extraction object","Driven embodied, Embodied system, Extraction object",NA,NA,"5","",""
"10.1109/icecs.2011.6122221","ec_fp7_ict__::3d96e331eef85eb603b58fd5b4b68b74","accelerated address;event processing;hardware accelerated","Hardware-accelerated address-event processing for high-speed visual object recognition","Hofstatter M.","2011-01-01","","publication","","","","","231467","Closed Access","0.5555","-0.3334","11","Accelerated address, Event processing, Hardware accelerated","Accelerated address, Event processing, Hardware accelerated",NA,NA,"2","",""
"10.1109/iscas.2010.5537265","ec_fp7_ict__::fe7f08d75ca4db1dd37c6a762153cdf7","ae processor;asynchronous time;atis camera","Live demonstration: Asynchronous Time-based Image Sensor (ATIS) camera with full-custom AE processor","Posch C.","2010-01-01","","publication","","","","","231467","Closed Access","-0.0714","-0.6712","4","Ae processor, Atis camera, Biomimetic frame","Ae processor, Atis camera, Biomimetic frame",NA,NA,"0","",""
"10.1109/iscas.2010.5537575","ec_fp7_ict__::66c958213d13a9c4ff49b4b07ddc3c59","asynchronous sensor;bit ns;m cmos","A SPARC-compatible general purpose address-event processor with 20-bit 10ns-resolution asynchronous sensor data interface in 0.18Î¼m CMOS","Hofstatter M.","2010-01-01","","publication","","","","","231467","Closed Access","0.0463","-0.4999","8","Asynchronous sensor, Bit ns, M cmos","Asynchronous sensor, Bit ns, M cmos",NA,NA,"4","",""
"10.1109/iscas.2011.5938190","ec_fp7_ict__::6d9ae2f06ec9337e4b1a3012f91cf0cc","attentive motion;mobile robotic;motion sensor","Attentive motion sensor for mobile robotic applications","Bartolozzi C.","2011-01-01","","publication","","","","","231467","Closed Access","0.5177","0.2222","7","Attentive motion, Mobile robotic, Motion sensor","Attentive motion, Mobile robotic, Motion sensor",NA,NA,"3","",""
"10.1109/jproc.2014.2313954","dedup_wf_001::c99ac91ebbe09aa18f492db3b0fd8caa","Computer Science - Emerging Technologies","Neuromorphic electronic circuits for building autonomous cognitive systems","Chicca, Elisabetta","2014-03-25","","publication","","","","Several analog and digital brain-inspired electronic systems have been recently proposed as dedicated solutions for fast simulations of spiking neural networks. While these architectures are useful for exploring the computational properties of large-scale models of the nervous system, the challenge of building low-power compact physical artifacts that can behave intelligently in the real world and exhibit cognitive abilities still remains open. In this paper, we propose a set of neuromorphic engineering solutions to address this challenge. In particular, we review neuromorphic circuits for emulating neural and synaptic dynamics in real time and discuss the role of biophysically realistic temporal dynamics in hardware neural processing architectures; we review the challenges of realizing spike-based plasticity mechanisms in real physical systems and present examples of analog electronic circuits that implement them; we describe the computational properties of recurrent neural networks and show how neuromorphic winner-take-all circuits can implement working-memory and decision-making mechanisms. We validate the neuromorphic approach proposed with experimental results obtained from our own circuits and systems, and argue how the circuits and networks presented in this work represent a useful set of components for efficiently and elegantly implementing neuromorphic cognition.","284553","Open Access","-0.3037","0.5565","13","Computer science - emerging technologies","Computer science - emerging technologies","10","179","83","",""
"10.1109/tbcas.2013.2255873","dedup_wf_001::d12377878720bbd49d900a9495575d56","Data processing, computer science","An Event-Based Neural Network Architecture With an Asynchronous Programmable Synaptic Memory","Moradi, Saber","2014-01-01","IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC","publication","","IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS","","","257219","Open Access","-0.6333","0.0332","12","Computer science, Data processing","Computer science, Data processing","1","63","28","",""
"10.3389/fnins.2013.00234","dedup_wf_001::073af3d43b07efa5ff037db4dc92fcb6","visual attention","Event-driven visual attention for the humanoid robot iCub","Rea, Francesco","2013-12-01","Frontiers Media S.A.","publication","","Frontiers in Neuroscience","","Fast reaction to sudden and potentially interesting stimuli is a crucial feature for safe and reliable interaction with the environment. Here we present a biologically inspired attention system developed for the humanoid robot iCub. It is based on input from unconventional event-driven vision sensors and an efficient computational method. The resulting system shows low-latency and fast determination of the location of the focus of attention. The performance is benchmarked against an instance of the state of the art in robotics artificial attention system used in robotics. Results show that the proposed system is two orders of magnitude faster that the benchmark in selecting a new stimulus to attend.","231467","Open Access","0.2388","0.1646","3","Visual attention","Visual attention","2","27","14","",""
"10.3389/fnins.2014.00009","dedup_wf_001::1182367904d553f3621130c1eb8430f1","neuromophic vision","Asynchronous visual event-based time-to-contact","Clady, Xavier","2014-02-01","Frontiers Media S.A.","publication","","Frontiers in Neuroscience","http://hal.upmc.fr/hal-01324452/document","International audience; Reliable and fast sensing of the environment is a fundamental requirement for autonomous mobile robotic platforms. Unfortunately, the frame-based acquisition paradigm at the basis of main stream artificial perceptive systems is limited by low temporal dynamics and redundant data flow, leading to high computational costs. Hence, conventional sensing and relative computation are obviously incompatible with the design of high speed sensor-based reactive control for mobile applications, that pose strict limits on energy consumption and computational load. This paper introduces a fast obstacle avoidance method based on the output of an asynchronous event-based time encoded imaging sensor. The proposed method relies on an event-based Time To Contact (TTC) computation based on visual event-based motion flows. The approach is event-based in the sense that every incoming event adds to the computation process thus allowing fast avoidance responses. The method is validated indoor on a mobile robot, comparing the event-based TTC with a laser range finder TTC, showing that event-based sensing offers new perspectives for mobile robotics sensing.","231467","Open Access","-0.2112","-0.0782","1","Neuromophic vision","Neuromophic vision","1","48","9","",""
"10.5167/uzh-31933","dedup_wf_001::38bfbf4f6984b7198f65bf57b042d152","Institute of Neuroinformatics","Selective Attention in Multi-Chip Address-Event Systems","Bartolozzi, Chiara","2009-06-26","Molecular Diversity Preservation International","publication","","Sensors","http://www.zora.uzh.ch/id/eprint/31933/3/Bartolozzi_Sensors_2009_V.pdf","Selective attention is the strategy used by biological systems to cope with the inherent limits in their available computational resources, in order to efficiently process sensory information. The same strategy can be used in artificial systems that have to process vast amounts of sensory data with limited resources. In this paper we present a neuromorphic VLSI device, the “Selective Attention Chip” (SAC), which can be used to implement these models in multi-chip address-event systems. We also describe a real-time sensory-motor system, which integrates the SAC with a dynamic vision sensor and a robotic actuator. We present experimental results from each component in the system, and demonstrate how the complete system implements a real-time stimulus-driven selective attention model. ","231467","Open Access","-0.0114","0.3302","3","Visual attention","Visual attention",NA,NA,"","",""
"10.5167/uzh-61188","dedup_wf_001::e73a54d15378c4d0a671cffc367416ef","log-domain","Neuromorphic silicon neuron circuits","Indiveri G","2011-01-01","","publication","","Frontiers in Neuroscience","http://www.zora.uzh.ch/id/eprint/61188/1/fnins-05-00073.pdf","
			Hardware implementations of spiking neurons can be extremely useful for a large variety of applications, ranging from high-speed modeling of large-scale neural systems to real-time behaving systems, to bidirectional brain–machine interfaces. The specific circuit solutions used to implement silicon neurons depend on the application requirements. In this paper we describe the most common building blocks and techniques used to implement these circuits, and present an overview of a wide range of neuromorphic silicon neurons, which implement different computational models, ranging from biophysically realistic and conductance-based Hodgkin–Huxley models to bi-dimensional generalized adaptive integrate and fire models. We compare the different design methodologies used for each silicon neuron design described, and demonstrate their features with experimental results, measured from a wide range of fabricated VLSI chips.
			","269921","Open Access","-0.4616","0.4224","14","Log-domain","Log-domain",NA,NA,"","",""
